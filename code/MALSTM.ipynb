{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93444adc-4709-4978-9a85-bdbb9df4ee5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# problem 파일 경로 Desktop/project/code_similarity/open/code\n",
    "\n",
    "# problem 폴더 안 예제 코드 확장자명 변경\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# .txt 병합\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "#keras model import\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1f79a5-0b25-4611-a721-e719ad89cd13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import Input, layers\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Input, Lambda,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#model save & load\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfe485f-27d4-48c5-b2a2-16eee9c30e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./open_code_train_220524.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ffefbc4-d3b4-4e58-898d-0786190b4e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               code1  c1_problem_name  \\\n",
      "0  n, m, k = map(int, input().split(\" \"))\\na = [i...              117   \n",
      "1                 N = int(input())\\nprint(int(N**2))              278   \n",
      "2  x, n = map(int, input().split())\\nlis =  []\\ni...              128   \n",
      "3  import sys\\ninput = sys.stdin.readline\\ndef ma...               71   \n",
      "4  import sys\\nINF = 1 << 60\\nMOD = 10**9 + 7 \\ns...               75   \n",
      "\n",
      "                                               code2  c2_problem_name  similar  \n",
      "0            a=int(input())\\nprint(a*6.283185307178)              167        0  \n",
      "1  from heapq import heappush, heappop\\nimport sy...              241        0  \n",
      "2  from collections import defaultdict,Counter\\nh...               89        0  \n",
      "3  word=input()\\nlast_letter=word[int(len(word))-...               71        1  \n",
      "4  import sys\\nimport math\\nimport collections\\ni...              118        0  \n",
      "1    30169\n",
      "0    29831\n",
      "Name: similar, dtype: int64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())\n",
    "print(train_data['similar'].value_counts())\n",
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96210302-5337-43ea-951b-a94017ccdd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41574fd0-a464-4f8f-b457-cc1e6512bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23fcf4e5-9ee3-448e-b5a5-e8a77eedc517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code1</th>\n",
       "      <th>c1_problem_name</th>\n",
       "      <th>code2</th>\n",
       "      <th>c2_problem_name</th>\n",
       "      <th>similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n, m, k = map(int, input().split(\" \"))\\na = [i...</td>\n",
       "      <td>117</td>\n",
       "      <td>a=int(input())\\nprint(a*6.283185307178)</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N = int(input())\\nprint(int(N**2))</td>\n",
       "      <td>278</td>\n",
       "      <td>from heapq import heappush, heappop\\nimport sy...</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x, n = map(int, input().split())\\nlis =  []\\ni...</td>\n",
       "      <td>128</td>\n",
       "      <td>from collections import defaultdict,Counter\\nh...</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>import sys\\ninput = sys.stdin.readline\\ndef ma...</td>\n",
       "      <td>71</td>\n",
       "      <td>word=input()\\nlast_letter=word[int(len(word))-...</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import sys\\nINF = 1 &lt;&lt; 60\\nMOD = 10**9 + 7 \\ns...</td>\n",
       "      <td>75</td>\n",
       "      <td>import sys\\nimport math\\nimport collections\\ni...</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               code1  c1_problem_name  \\\n",
       "0  n, m, k = map(int, input().split(\" \"))\\na = [i...              117   \n",
       "1                 N = int(input())\\nprint(int(N**2))              278   \n",
       "2  x, n = map(int, input().split())\\nlis =  []\\ni...              128   \n",
       "3  import sys\\ninput = sys.stdin.readline\\ndef ma...               71   \n",
       "4  import sys\\nINF = 1 << 60\\nMOD = 10**9 + 7 \\ns...               75   \n",
       "\n",
       "                                               code2  c2_problem_name  similar  \n",
       "0            a=int(input())\\nprint(a*6.283185307178)              167        0  \n",
       "1  from heapq import heappush, heappop\\nimport sy...              241        0  \n",
       "2  from collections import defaultdict,Counter\\nh...               89        0  \n",
       "3  word=input()\\nlast_letter=word[int(len(word))-...               71        1  \n",
       "4  import sys\\nimport math\\nimport collections\\ni...              118        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0dbe0f4-d4fc-4501-bacc-700b5761e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['c1_problem_name','c2_problem_name'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8cc590-57ad-4792-bb6d-ed73bb72dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "                                               code1  \\\n",
      "0  n, m, k = map(int, input().split(\" \"))\\na = [i...   \n",
      "1                 N = int(input())\\nprint(int(N**2))   \n",
      "2  x, n = map(int, input().split())\\nlis =  []\\ni...   \n",
      "3  import sys\\ninput = sys.stdin.readline\\ndef ma...   \n",
      "4  import sys\\nINF = 1 << 60\\nMOD = 10**9 + 7 \\ns...   \n",
      "\n",
      "                                               code2  similar  \n",
      "0            a=int(input())\\nprint(a*6.283185307178)        0  \n",
      "1  from heapq import heappush, heappop\\nimport sy...        0  \n",
      "2  from collections import defaultdict,Counter\\nh...        0  \n",
      "3  word=input()\\nlast_letter=word[int(len(word))-...        1  \n",
      "4  import sys\\nimport math\\nimport collections\\ni...        0  \n"
     ]
    }
   ],
   "source": [
    "print(type(train_data['code1']))\n",
    "print(type(train_data['code2']))\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "910b87f9-6e2e-4005-8563-00c0b0032846",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer() # Tokenizer 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e73ca3-9d3c-4365-85e5-aa1cd1abf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_data['code1']) # 단어 인덱스 구축\n",
    "tokenizer.fit_on_texts(train_data['code2']) # 단어 인덱스 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17b4ac49-06cf-4f64-9164-35e73b2b8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_1 = tokenizer.texts_to_sequences(train_data['code1']) # 문자열을 정수 인덱스의 리스트로 변환한다. \n",
    "sequences_2 = tokenizer.texts_to_sequences(train_data['code2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d29caf-c1ea-405a-94f4-ca3da38e2d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: similar, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val = train_data['similar']\n",
    "train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a7be783-be3e-49c1-8f32-49b4ff29c086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12440\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "161a92d4-85ae-455e-aac7-98ee75aae216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드의 최대 길이 : 803\n",
      "코드의 평균길이 : 63.076366666666665\n",
      "코드의 평균길이 : 63\n"
     ]
    }
   ],
   "source": [
    "#가장 긴 sequence의 길이\n",
    "MAX_SEQUENCE_LENGTH = max([len(seq) for seq in sequences_1 + sequences_2])\n",
    "ABR__SEQUENCE_LENGTH = round(sum(map(len, sequences_1))/len(sequences_1))\n",
    "print('코드의 최대 길이 : {}'.format(max([len(seq) for seq in sequences_1 + sequences_2])))\n",
    "print('코드의 평균길이 : {}'.format(sum(map(len, sequences_1))/len(sequences_1)))\n",
    "print('코드의 평균길이 : %d'% ABR__SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af9eac31-b711-4810-b785-b3d3209311fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = MAX_SEQUENCE_LENGTH\n",
    "ABR__SEQUENCE_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14f9aaa7-e981-4eeb-a7bd-34b036edd8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 256)\n",
      "(60000, 256)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_train_1 = pad_sequences(sequences_1, maxlen=ABR__SEQUENCE_LENGTH)\n",
    "X_train_2 = pad_sequences(sequences_2, maxlen=ABR__SEQUENCE_LENGTH)\n",
    "print(X_train_1.shape)\n",
    "print(X_train_2.shape)\n",
    "print(type(X_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3874020-2d2f-49ee-8493-70d90c74488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model variables\n",
    "batch_size = 512\n",
    "epoch = 10\n",
    "vocab_size = vocab_size\n",
    "MAX_SEQUENCE_LENGTH = MAX_SEQUENCE_LENGTH\n",
    "ABR__SEQUENCE_LENGTH = ABR__SEQUENCE_LENGTH\n",
    "vocab_size = vocab_size\n",
    "emb_output_dim = 128\n",
    "DROPOUT_RATIO = 0.25\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
    "\n",
    "# The visible layer\n",
    "input_tensor1 = layers.Input(shape= (256,), dtype = 'int32', name = 'code1')\n",
    "input_tensor2 = layers.Input(shape= (256,), dtype = 'int32', name = 'code2')\n",
    "\n",
    "# Embedding layers\n",
    "embedding_layer = layers.Embedding(input_dim = vocab_size,\n",
    "                                   output_dim = emb_output_dim,\n",
    "                                   input_length = ABR__SEQUENCE_LENGTH,\n",
    "                                   mask_zero = True,\n",
    "                                   trainable = False)\n",
    "\n",
    "# Embedded of the inputs\n",
    "encoded_1 = embedding_layer(input_tensor1)\n",
    "encoded_2 = embedding_layer(input_tensor2)\n",
    "\n",
    "# define lstm for sentence encode\n",
    "encoded_LSTM1 = layers.LSTM(64, activation='tanh')(encoded_1)\n",
    "encoded_LSTM2 = layers.LSTM(64, activation='tanh')(encoded_2)\n",
    "\n",
    "#dropout layer\n",
    "drop1 = layers.Dropout(DROPOUT_RATIO)(encoded_LSTM1)\n",
    "drop2 = layers.Dropout(DROPOUT_RATIO)(encoded_LSTM2)\n",
    "\n",
    "# Calculates the distance as defined by the MaLSTM model\n",
    "#concats = layers.concatenate([encoded_LSTM1,encoded_LSTM2], axis = -1)\n",
    "\n",
    "#함수형 API 모델 을 구성할 때 임의 의 Lambda표현식을 사용할 수 있도록 레이어 생성\n",
    "main_malstm_distance = layers.Lambda(lambda x: exponent_neg_manhattan_distance(x[0], x[1]), output_shape=lambda x: (x[0][0], 1))([drop1,drop2])\n",
    "\n",
    "#output\n",
    "#answer = layers.Dense(1, activation='sigmoid')(main_malstm_distance)\n",
    "# 최종 아웃풋을 어떤것으로 지정할것인가?\n",
    "\n",
    "#model\n",
    "malstm = Model([input_tensor1, input_tensor2], outputs = main_malstm_distance)\n",
    "\n",
    "#model compile \n",
    "malstm.compile(loss='mean_squared_logarithmic_error', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a45e5324-824c-4afe-8121-86a8c8748319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " code1 (InputLayer)             [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " code2 (InputLayer)             [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 256, 128)     1592320     ['code1[0][0]',                  \n",
      "                                                                  'code2[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 64)           49408       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 64)           49408       ['embedding_2[1][0]']            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 1)            0           ['dropout_4[0][0]',              \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,691,136\n",
      "Trainable params: 98,816\n",
      "Non-trainable params: 1,592,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "malstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9aab12e7-df31-4a17-a047-1b40fa76b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",patience = 10, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fdf6b4-7ac5-4208-8613-6439a53f8f90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " 4/94 [>.............................] - ETA: 17:16 - loss: 0.1324 - accuracy: 0.5078"
     ]
    }
   ],
   "source": [
    "history = malstm.fit([X_train_1,X_train_2],\n",
    "                   train_val,\n",
    "                   verbose=1,\n",
    "                   callbacks=[early_stopping],\n",
    "                   validation_split=0.2,\n",
    "                   epochs=150,\n",
    "                   batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d5475f-9b34-4bb2-a2fb-14172967fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_smilarity_MSLE_803')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc20f0-4f68-4c11-8664-27e0dc136a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e23a4-5920-45b7-886e-4c44b2194453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be69e49-8852-4ce9-ab4b-a0bd2c49bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data 정수\n",
    "tokenizer.fit_on_texts(test_data['code1']) # 단어 인덱스 구축\n",
    "tokenizer.fit_on_texts(test_data['code2']) # 단어 인덱스 구축\n",
    "\n",
    "test_sequences_1 = tokenizer.texts_to_sequences(test_data['code1']) # 문자열을 정수 인덱스의 리스트로 변환한다. \n",
    "test_sequences_2 = tokenizer.texts_to_sequences(test_data['code2'])\n",
    "\n",
    "X_test_1 = pad_sequences(test_sequences_1, maxlen=ABR__SEQUENCE_LENGTH)\n",
    "X_test_2 = pad_sequences(test_sequences_2, maxlen=ABR__SEQUENCE_LENGTH)\n",
    "\n",
    "print(X_test_1.shape)\n",
    "print(X_test_2.shape)\n",
    "print(type(X_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77ef81-4996-49af-a9ae-a25e7dee11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 추론\n",
    "preds = malstm.predict(test_data['code1'], test_data['code2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f204bc-cbe3-418b-b55c-debcca3e35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "preds = np.where(preds>self.threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93618be5-d69a-4e16-a0a2-243a5ecd14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 저장\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['similar'] = preds\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
